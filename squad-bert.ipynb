{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T08:14:51.591488Z",
     "iopub.status.busy": "2023-08-31T08:14:51.591060Z",
     "iopub.status.idle": "2023-08-31T08:15:01.191781Z",
     "shell.execute_reply": "2023-08-31T08:15:01.190759Z",
     "shell.execute_reply.started": "2023-08-31T08:14:51.591462Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T08:15:01.195996Z",
     "iopub.status.busy": "2023-08-31T08:15:01.193732Z",
     "iopub.status.idle": "2023-08-31T08:15:01.213596Z",
     "shell.execute_reply": "2023-08-31T08:15:01.212014Z",
     "shell.execute_reply.started": "2023-08-31T08:15:01.195957Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    def __init__(self, question, context, start_char_idx=None, answer_text=None, all_answers=None):\n",
    "        self.question = question\n",
    "        self.context = context\n",
    "        self.start_char_idx = start_char_idx\n",
    "        self.answer_text = answer_text\n",
    "        self.all_answers = all_answers\n",
    "        self.skip = False\n",
    "        self.start_token_idx = -1\n",
    "        self.end_token_idx = -1\n",
    "\n",
    "    def preprocess(self):\n",
    "        context = \" \".join(str(self.context).split())\n",
    "        question = \" \".join(str(self.question).split())\n",
    "        tokenized_context = tokenizer.encode(context)\n",
    "        tokenized_question = tokenizer.encode(question)\n",
    "        if self.answer_text is not None:\n",
    "            answer = \" \".join(str(self.answer_text).split())\n",
    "            end_char_idx = self.start_char_idx + len(answer)\n",
    "            if end_char_idx >= len(context):\n",
    "                self.skip = True\n",
    "                return\n",
    "            is_char_in_ans = [0] * len(context)\n",
    "            for idx in range(self.start_char_idx, end_char_idx):\n",
    "                is_char_in_ans[idx] = 1\n",
    "            ans_token_idx = []\n",
    "            for idx, (start, end) in enumerate(tokenized_context.offsets):\n",
    "                if sum(is_char_in_ans[start:end]) > 0:\n",
    "                    ans_token_idx.append(idx)\n",
    "            if len(ans_token_idx) == 0:\n",
    "                self.skip = True\n",
    "                return\n",
    "            self.start_token_idx = ans_token_idx[0]\n",
    "            self.end_token_idx = ans_token_idx[-1]\n",
    "        input_ids = tokenized_context.ids + tokenized_question.ids[1:]\n",
    "        token_type_ids = [0] * len(tokenized_context.ids) + [1] * len(tokenized_question.ids[1:])\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        padding_length = max_seq_length - len(input_ids)\n",
    "        if padding_length > 0:\n",
    "            input_ids = input_ids + ([0] * padding_length)\n",
    "            attention_mask = attention_mask + ([0] * padding_length)\n",
    "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        elif padding_length < 0:\n",
    "            self.skip = True\n",
    "            return\n",
    "        self.input_word_ids = input_ids\n",
    "        self.input_type_ids = token_type_ids\n",
    "        self.input_mask = attention_mask\n",
    "        self.context_token_to_char = tokenized_context.offsets\n",
    "\n",
    "\n",
    "def create_squad_examples(raw_data):\n",
    "    squad_examples = []\n",
    "    for item in raw_data[\"data\"]:\n",
    "        for para in item[\"paragraphs\"]:\n",
    "            context = para[\"context\"]\n",
    "            for qa in para[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                if \"answers\" in qa:\n",
    "                    answer_text = qa[\"answers\"][0][\"text\"]\n",
    "                    all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
    "                    start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
    "                    squad_eg = Sample(question, context, start_char_idx, answer_text, all_answers)\n",
    "                else:\n",
    "                    squad_eg = Sample(question, context)\n",
    "                squad_eg.preprocess()\n",
    "                squad_examples.append(squad_eg)\n",
    "    return squad_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T08:15:01.216755Z",
     "iopub.status.busy": "2023-08-31T08:15:01.216378Z",
     "iopub.status.idle": "2023-08-31T08:15:01.233542Z",
     "shell.execute_reply": "2023-08-31T08:15:01.232733Z",
     "shell.execute_reply.started": "2023-08-31T08:15:01.216722Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_inputs_targets(squad_examples):\n",
    "    dataset_dict = {\n",
    "        \"input_word_ids\": [],\n",
    "        \"input_type_ids\": [],\n",
    "        \"input_mask\": [],\n",
    "        \"start_token_idx\": [],\n",
    "        \"end_token_idx\": [],\n",
    "    }\n",
    "    for item in squad_examples:\n",
    "        if item.skip == False:\n",
    "            for key in dataset_dict:\n",
    "                dataset_dict[key].append(getattr(item, key))\n",
    "    for key in dataset_dict:\n",
    "        dataset_dict[key] = np.array(dataset_dict[key])\n",
    "    x = [dataset_dict[\"input_word_ids\"],\n",
    "         dataset_dict[\"input_mask\"],\n",
    "         dataset_dict[\"input_type_ids\"]]\n",
    "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "class ValidationCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def normalize_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = \"\".join(ch for ch in text if ch not in set(string.punctuation))\n",
    "        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
    "        text = re.sub(regex, \" \", text)\n",
    "        text = \" \".join(text.split())\n",
    "        return text\n",
    "\n",
    "    def __init__(self, x_eval, y_eval):\n",
    "        self.x_eval = x_eval\n",
    "        self.y_eval = y_eval\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
    "        count = 0\n",
    "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
    "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
    "            squad_eg = eval_examples_no_skip[idx]\n",
    "            offsets = squad_eg.context_token_to_char\n",
    "            start = np.argmax(start)\n",
    "            end = np.argmax(end)\n",
    "            if start >= len(offsets):\n",
    "                continue\n",
    "            pred_char_start = offsets[start][0]\n",
    "            if end < len(offsets):\n",
    "                pred_char_end = offsets[end][1]\n",
    "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
    "            else:\n",
    "                pred_ans = squad_eg.context[pred_char_start:]\n",
    "            normalized_pred_ans = self.normalize_text(pred_ans)\n",
    "            normalized_true_ans = [self.normalize_text(_) for _ in squad_eg.all_answers]\n",
    "            if normalized_pred_ans in normalized_true_ans:\n",
    "                count += 1\n",
    "        acc = count / len(self.y_eval[0])\n",
    "        print(f\"\\nepoch={epoch + 1}, exact match score={acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T08:15:01.236714Z",
     "iopub.status.busy": "2023-08-31T08:15:01.236357Z",
     "iopub.status.idle": "2023-08-31T10:31:06.110368Z",
     "shell.execute_reply": "2023-08-31T10:31:06.109186Z",
     "shell.execute_reply.started": "2023-08-31T08:15:01.236653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
      "30288272/30288272 [==============================] - 0s 0us/step\n",
      "Downloading data from https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
      "4854279/4854279 [==============================] - 0s 0us/step\n",
      "87599 training points created.\n",
      "10570 evaluation points created.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 384)]        0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, 384)]        0           []                               \n",
      "                                                                                                  \n",
      " input_type_ids (InputLayer)    [(None, 384)]        0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
      "                                 (None, 384, 768)]                'input_mask[0][0]',             \n",
      "                                                                  'input_type_ids[0][0]']         \n",
      "                                                                                                  \n",
      " start_logit (Dense)            (None, 384, 1)       768         ['keras_layer[0][1]']            \n",
      "                                                                                                  \n",
      " end_logit (Dense)              (None, 384, 1)       768         ['keras_layer[0][1]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 384)          0           ['start_logit[0][0]']            \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 384)          0           ['end_logit[0][0]']              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 384)          0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 384)          0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,483,777\n",
      "Trainable params: 109,483,776\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n",
      "323/323 [==============================] - 289s 892ms/step\n",
      "\n",
      "epoch=1, exact match score=0.00\n",
      "10767/10767 [==============================] - 8051s 743ms/step - loss: 11.9261 - activation_loss: 5.9629 - activation_1_loss: 5.9632\n"
     ]
    }
   ],
   "source": [
    "train_path = keras.utils.get_file(\"train.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\")\n",
    "eval_path = keras.utils.get_file(\"eval.json\", \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\")\n",
    "with open(train_path) as f: raw_train_data = json.load(f)\n",
    "with open(eval_path) as f: raw_eval_data = json.load(f)\n",
    "max_seq_length = 384\n",
    "\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_word_ids')\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_mask')\n",
    "input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name='input_type_ids')\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy().decode(\"utf-8\")\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertWordPieceTokenizer(vocab=vocab_file, lowercase=True)\n",
    "train_squad_examples = create_squad_examples(raw_train_data)\n",
    "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
    "print(f\"{len(train_squad_examples)} training points created.\")\n",
    "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
    "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
    "print(f\"{len(eval_squad_examples)} evaluation points created.\")\n",
    "start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(sequence_output)\n",
    "start_logits = layers.Flatten()(start_logits)\n",
    "end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(sequence_output)\n",
    "end_logits = layers.Flatten()(end_logits)\n",
    "start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
    "end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
    "model = keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=[start_probs, end_probs])\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optimizer = keras.optimizers.Adam(lr=1e-5, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "model.compile(optimizer=optimizer, loss=[loss, loss])\n",
    "model.summary()\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=8, callbacks=[ValidationCallback(x_eval, y_eval)])\n",
    "model.save_weights(\"./weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T10:31:06.112601Z",
     "iopub.status.busy": "2023-08-31T10:31:06.112198Z",
     "iopub.status.idle": "2023-08-31T10:31:06.122673Z",
     "shell.execute_reply": "2023-08-31T10:31:06.121649Z",
     "shell.execute_reply.started": "2023-08-31T10:31:06.112563Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {\"data\":\n",
    "    [\n",
    "        {\"title\": \"Project Apollo\",\n",
    "         \"paragraphs\": [\n",
    "             {\n",
    "                 \"context\": \"The Apollo program, also known as Project Apollo, was the third United States human \"\n",
    "                            \"spaceflight program carried out by the National Aeronautics and Space Administration (\"\n",
    "                            \"NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First \"\n",
    "                            \"conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to \"\n",
    "                            \"follow the one-man Project Mercury which put the first Americans in space, Apollo was \"\n",
    "                            \"later dedicated to President John F. Kennedy's national goal of landing a man on the \"\n",
    "                            \"Moon and returning him safely to the Earth by the end of the 1960s, which he proposed in \"\n",
    "                            \"a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project \"\n",
    "                            \"Gemini. The first manned flight of Apollo was in 1968. Apollo ran from 1961 to 1972, \"\n",
    "                            \"and was supported by the two man Gemini program which ran concurrently with it from 1962 \"\n",
    "                            \"to 1966. Gemini missions developed some of the space travel techniques that were \"\n",
    "                            \"necessary for the success of the Apollo missions. Apollo used Saturn family rockets as \"\n",
    "                            \"launch vehicles. Apollo/Saturn vehicles were also used for an Apollo Applications \"\n",
    "                            \"Program, which consisted of Skylab, a space station that supported three manned missions \"\n",
    "                            \"in 1973-74, and the Apollo-Soyuz Test Project, a joint Earth orbit mission with the \"\n",
    "                            \"Soviet Union in 1975.\",\n",
    "                 \"qas\": [\n",
    "                     {\"question\": \"What project put the first Americans into space?\",\n",
    "                      \"id\": \"Q1\"\n",
    "                      },\n",
    "                     {\"question\": \"What program was created to carry out these projects and missions?\",\n",
    "                      \"id\": \"Q2\"\n",
    "                      },\n",
    "                     {\"question\": \"What year did the first manned Apollo flight occur?\",\n",
    "                      \"id\": \"Q3\"\n",
    "                      },\n",
    "                     {\"question\": \"What President is credited with the original notion of putting Americans in space?\",\n",
    "                      \"id\": \"Q4\"\n",
    "                      },\n",
    "                     {\"question\": \"Who did the U.S. collaborate with on an Earth orbit mission in 1975?\",\n",
    "                      \"id\": \"Q5\"\n",
    "                      },\n",
    "                     {\"question\": \"How long did Project Apollo run?\",\n",
    "                      \"id\": \"Q6\"\n",
    "                      },\n",
    "                     {\"question\": \"What program helped develop space travel techniques that Project Apollo used?\",\n",
    "                      \"id\": \"Q7\"\n",
    "                      },\n",
    "                     {\"question\": \"What space station supported three manned missions in 1973-1974?\",\n",
    "                      \"id\": \"Q8\"\n",
    "                      }\n",
    "                 ]}]}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T10:31:06.125329Z",
     "iopub.status.busy": "2023-08-31T10:31:06.124320Z",
     "iopub.status.idle": "2023-08-31T10:31:06.526026Z",
     "shell.execute_reply": "2023-08-31T10:31:06.525038Z",
     "shell.execute_reply.started": "2023-08-31T10:31:06.125292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 325ms/step\n",
      "Q: What project put the first Americans into space?\n",
      "A: \n",
      "Q: What program was created to carry out these projects and missions?\n",
      "A: also known as Project Apollo, was the third United States human spaceflight program carried out by the National Aeronautics and Space Administration (NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to follow the one-man Project Mercury which put the first Americans in space, Apollo was later dedicated to President John F. Kennedy's national goal of landing a man on the Moon and returning him safely to the Earth by the end of the 1960s, which he proposed in a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project Gemini. The first manned flight of Apollo was in 1968. Apollo ran from 1961 to 1972, and was supported by the two man Gemini program which ran concurrently with it from 1962 to 1966. Gemini missions developed some of the space travel techniques that\n",
      "Q: What year did the first manned Apollo flight occur?\n",
      "A: The Apollo program, also known as Project Apollo, was the third United States human spaceflight program carried out by the National Aeronautics and Space Administration (NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to follow the one-man Project Mercury which put the first Americans in space, Apollo was later dedicated to President John F. Kennedy's national goal of landing a man on the Moon and returning him safely to the Earth by the end of the 1960s, which he proposed in a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project Gemini. The first manned flight of Apollo was in 1968. Apollo ran from 1961 to 1972, and was supported by the two man Gemini program which ran concurrently with it from 1962 to 1966. Gemini missions developed some of the space travel techniques that\n",
      "Q: What President is credited with the original notion of putting Americans in space?\n",
      "A: \n",
      "Q: Who did the U.S. collaborate with on an Earth orbit mission in 1975?\n",
      "A: \n",
      "Q: How long did Project Apollo run?\n",
      "A: was the third United States human spaceflight program carried out by the National Aeronautics and Space Administration (NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to follow the one-man Project Mercury which put the first Americans in space, Apollo was later dedicated to President John F. Kennedy's national goal of landing a man on the Moon and returning him safely to the Earth by the end of the 1960s, which he proposed in a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project Gemini. The first manned flight of Apollo was in 1968. Apollo ran from 1961 to 1972, and was supported by the two man Gemini program which ran concurrently with it from 1962 to 1966. Gemini missions developed some of the space travel techniques that were necessary for the success of\n",
      "Q: What program helped develop space travel techniques that Project Apollo used?\n",
      "A: Project Apollo, was the third United States human spaceflight program carried out by the National Aeronautics and Space Administration (NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to follow the one-man Project Mercury which put the first Americans in space, Apollo was later dedicated to President John F. Kennedy's national goal of landing a man on the Moon and returning him safely to the Earth by the end of the 1960s, which he proposed in a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project Gemini. The first manned flight of Apollo was in 1968. Apollo ran from 1961 to 1972, and was supported by the two man Gemini program which ran concurrently with it from 1962 to 1966. Gemini missions developed some of the space travel techniques that were necessary for the success of the Apollo missions. Apollo used Saturn family rockets as launch vehicles. Apollo/Saturn vehicles were also used for an Apollo Applications Program, which consisted of Skylab, a space station that supported three manned missions in 1973-74, and the Apollo-Soyuz Test Project, a joint Earth orbit mission with the Soviet Union in\n",
      "Q: What space station supported three manned missions in 1973-1974?\n",
      "A: program, also known as Project Apollo, was the third United States human spaceflight program carried out by the National Aeronautics and Space Administration (NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to follow the one-man Project Mercury which put the first Americans in space, Apollo was later dedicated to President John F. Kennedy's national goal of landing a man on the Moon and returning him safely to the Earth by the end of the 1960s, which he proposed in a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project Gemini. The first manned flight of Apollo was in 1968. Apollo ran from 1961 to 1972, and was supported by the two man Gemini program which ran concurrently with it from\n"
     ]
    }
   ],
   "source": [
    "test_samples = create_squad_examples(data)\n",
    "x_test, _ = create_inputs_targets(test_samples)\n",
    "pred_start, pred_end = model.predict(x_test)\n",
    "for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
    "    test_sample = test_samples[idx]\n",
    "    offsets = test_sample.context_token_to_char\n",
    "    start = np.argmax(start)\n",
    "    end = np.argmax(end)\n",
    "    pred_ans = None\n",
    "    if start >= len(offsets):\n",
    "        continue\n",
    "    pred_char_start = offsets[start][0]\n",
    "    if end < len(offsets):\n",
    "        pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\n",
    "    else:\n",
    "        pred_ans = test_sample.context[pred_char_start:]\n",
    "    print(\"Q: \" + test_sample.question)\n",
    "    print(\"A: \" + pred_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
